
Q1. Write a Python code to implement the KNN classifier algorithm on load_iris dataset in sklearn.datasets.

from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,accuracy_score,r2_score,max_error,mean_squared_error
import pandas as pd
X=load_iris().data
y=load_iris().target
X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.33, random_state=42)
k_clf1=KNeighborsClassifier()
k_clf1.fit(X_train,y_train)
KNeighborsClassifier()
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.
y_pred1=k_clf1.predict(X_test)
print("Classification Report: ",classification_report(y_test,y_pred1))
print("Accuracy: ",accuracy_score(y_test,y_pred1))
Classification Report:                precision    recall  f1-score   support

           0       1.00      1.00      1.00        19
           1       0.94      1.00      0.97        15
           2       1.00      0.94      0.97        16

    accuracy                           0.98        50
   macro avg       0.98      0.98      0.98        50
weighted avg       0.98      0.98      0.98        50

Accuracy:  0.98
Q2. Write a Python code to implement the KNN regressor algorithm on load_boston dataset in sklearn.datasets.

from sklearn.datasets import fetch_california_housing # Since boston dataset has been removed from skleear so I used california housing dataset
from sklearn.neighbors import KNeighborsRegressor
X=fetch_california_housing().data
y=fetch_california_housing().target
X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.18, random_state=42)
k_clf2=KNeighborsRegressor()
k_clf2.fit(X_train,y_train)
KNeighborsRegressor()
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.
y_pred2=k_clf2.predict(X_test)
print("R2: ",r2_score(y_test,y_pred2))
print("Mean squared error: ",mean_squared_error(y_test,y_pred2))
print("Max error: ",max_error(y_test,y_pred2))
R2:  0.16227672449056885
Mean squared error:  1.099016801036961
Max error:  3.61081
Q3. Write a Python code snippet to find the optimal value of K for the KNN classifier algorithm using cross-validation on load_iris dataset in sklearn.datasets.

from sklearn.model_selection import GridSearchCV
X3=load_iris().data
y3=load_iris().target
X_train, X_test, y_train, y_test = train_test_split(
        X3, y3, test_size=0.33, random_state=42)
clf=GridSearchCV(KNeighborsClassifier(),param_grid={'n_neighbors':[2,3,4,5,6]},cv=3)
clf.fit(X_train,y_train)
GridSearchCV(cv=3, estimator=KNeighborsClassifier(),
             param_grid={'n_neighbors': [2, 3, 4, 5, 6]})
In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.
On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.
clf.best_params_
{'n_neighbors': 2}
The optimal value of K for KNN classifier on load_iris dataset is 2

Q4. Implement the KNN regressor algorithm with feature scaling on load_boston dataset in sklearn.datasets.

X4=fetch_california_housing().data
y4=fetch_california_housing().target
X_train, X_test, y_train, y_test = train_test_split(
    X4, y4, test_size=0.20, random_state=42)
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
X_train_scaled=scaler.fit_transform(X_train)
X_test_scaled=scaler.transform(X_test)
k_clf3=KNeighborsRegressor()
k_clf3.fit(X_train_scaled,y_train)
y_pred3=k_clf3.predict(X_test_scaled)
print("R2: ",r2_score(y_test,y_pred3))
print("Mean squared error: ",mean_squared_error(y_test,y_pred3))
print("Max error: ",max_error(y_test,y_pred3))
R2:  0.6700101862970989
Mean squared error:  0.4324216146043236
Max error:  4.09641
Q5. Write a Python code snippet to implement the KNN classifier algorithm with weighted voting on load_iris dataset in sklearn.datasets.

X5=load_iris().data
y5=load_iris().target
X_train, X_test, y_train, y_test = train_test_split(
        X5, y5, test_size=0.33, random_state=42)
k_clf5=KNeighborsClassifier(weights='distance')
k_clf5.fit(X_train,y_train)
y_pred5=k_clf1.predict(X_test)
print("Classification Report: ",classification_report(y_test,y_pred5))
print("Accuracy: ",accuracy_score(y_test,y_pred5))
Classification Report:                precision    recall  f1-score   support

           0       1.00      1.00      1.00        19
           1       0.94      1.00      0.97        15
           2       1.00      0.94      0.97        16

    accuracy                           0.98        50
   macro avg       0.98      0.98      0.98        50
weighted avg       0.98      0.98      0.98        50

Accuracy:  0.98
Q6. Implement a function to standardise the features before applying KNN classifier.

def preprocessed(X_train,X_test):
    scaler = StandardScaler()
    X_train_scaled=scaler.fit_transform(X_train)
    X_test_scaled=scaler.transform(X_test)

    return X_train_scaled,X_train_scaled
Q7. Write a Python function to calculate the euclidean distance between two points.

import numpy as np
def euclidian(x1,x2,y1,y2):
    distance=np.sqrt(((x2-x1)**2)+((y2-y1)**2))
    return distance
euclidian(3,4,5,6)
1.4142135623730951
Q8. Write a Python function to calculate the manhattan distance between two points.
